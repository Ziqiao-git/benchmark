# chat_models/config.py

# Import the model implementations
from chatgpt_model import ChatGPTChatModel
from claude_model import ClaudeChatModel
from deepseek_model import DeepSeekChatModel
from gemini_model import GeminiChatModel
from xai_model import XAIChatModel

# Registry of all model implementations
MODEL_REGISTRY = {
    "chatgpt": ChatGPTChatModel,
    "claude": ClaudeChatModel,
    "deepseek": DeepSeekChatModel,
    "gemini": GeminiChatModel,
    "xai": XAIChatModel,
}

# Different model configurations for each provider
MODEL_CONFIGS = {
    "chatgpt": {
        "default": {
            "model": "gpt-3.5-turbo",
            "temperature": 1.0,
        },
        "standard": {
            "model": "gpt-3.5-turbo",
            "temperature": 1.0,
        },
        "fast": {
            "model": "o1-mini",
            "temperature": 0.7,
        },
        "powerful": {
            "model": "o1",
            "temperature": 0.5,
        },
    },
    "claude": {
        "default": {
            "model": "claude-3-7-sonnet-20250219",
            "temperature": 0.0,
        },
        "standard": {
            "model": "claude-3-7-sonnet-20250219",
            "temperature": 0.0,
        },
        "fast": {
            "model": "claude-3-5-haiku-20250521",
            "temperature": 0.0,
        },
        "powerful": {
            "model": "claude-3-opus-20250829",
            "temperature": 0.0,
        },
    },
    "deepseek": {
        "default": {
            "model": "deepseek-reasoner",
            "temperature": 0.2,
        },
        "standard": {
            "model": "deepseek-reasoner",
            "temperature": 0.2,
        },
        "powerful": {
            "model": "deepseek-coder",
            "temperature": 0.1,
        },
    },
    "gemini": {
        "default": {
            "model": "gemini-2.0-flash",
            "temperature": 0.2,
        },
        "standard": {
            "model": "gemini-2.0-flash",
            "temperature": 0.2,
        },
        "powerful": {
            "model": "gemini-2.0-pro",
            "temperature": 0.1,
        },
    },
    "xai": {
        "default": {
            "model": "grok-2",
            "temperature": 0.2,
        },
        "standard": {
            "model": "grok-2",
            "temperature": 0.2,
        },
        "powerful": {
            "model": "grok-2-1212",
            "temperature": 0.1,
        },
    }
}

# API key parameter names for each provider
API_KEY_PARAMS = {
    "chatgpt": "openai_api_key",
    "claude": "anthropic_api_key",
    "deepseek": "deepseek_api_key",
    "gemini": "gemini_api_key",
    "xai": "xai_api_key",
}